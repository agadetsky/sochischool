{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://agadetsky@github.com/agadetsky/sochischool.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CNxcSwfbLxs",
        "outputId": "1acfd3e8-f6fa-4f61-bb49-e50caa839ad8"
      },
      "id": "1CNxcSwfbLxs",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sochischool'...\n",
            "remote: Enumerating objects: 235, done.\u001b[K\n",
            "remote: Counting objects:  25% (1/4)\u001b[K\rremote: Counting objects:  50% (2/4)\u001b[K\rremote: Counting objects:  75% (3/4)\u001b[K\rremote: Counting objects: 100% (4/4)\u001b[K\rremote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 235 (delta 0), reused 2 (delta 0), pack-reused 231\u001b[K\n",
            "Receiving objects: 100% (235/235), 50.75 MiB | 32.38 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n",
            "Checking out files: 100% (194/194), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU git+https://github.com/harvardnlp/pytorch-struct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEwPcViWbb-r",
        "outputId": "9e9cabdf-c6a9-41cb-eb03-275fe56f8638"
      },
      "id": "QEwPcViWbb-r",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for torch-struct (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/sochischool/')"
      ],
      "metadata": {
        "id": "KVy40zmHbP6p"
      },
      "id": "KVy40zmHbP6p",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8a5a99b7",
      "metadata": {
        "id": "8a5a99b7"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e6d5e694",
      "metadata": {
        "id": "e6d5e694"
      },
      "outputs": [],
      "source": [
        "import listops.data as _data\n",
        "import listops.data_processing.python.loading as _loading\n",
        "import listops.model as _model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "071d899d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "071d899d",
        "outputId": "a74ea352-64a4-4799-8a30-a9804a730c80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sochischool/listops/data_processing/python/listops/data/d2_ml50_nosm\n",
            "/content/sochischool/listops/data_processing/python/listops/data/d3_ml50_nosm\n",
            "/content/sochischool/listops/data_processing/python/listops/data/d4_ml50_nosm\n",
            "/content/sochischool/listops/data_processing/python/listops/data/d5_ml50_nosm\n",
            "/content/sochischool/listops/data_processing/python/listops/data/d1_ml50_nosm\n",
            "maxnums\n",
            "[20000, 2000, 2000]\n",
            "[2, 3, 4, 5]\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d2_ml50_nosm/train.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d3_ml50_nosm/train.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d4_ml50_nosm/train.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d5_ml50_nosm/train.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d1_ml50_nosm/train.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "[2, 3, 4, 5]\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d2_ml50_nosm/valid.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d3_ml50_nosm/valid.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d4_ml50_nosm/valid.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d5_ml50_nosm/valid.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d1_ml50_nosm/valid.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "[2, 3, 4, 5]\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d2_ml50_nosm/test.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d3_ml50_nosm/test.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d4_ml50_nosm/test.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d5_ml50_nosm/test.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d1_ml50_nosm/test.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n"
          ]
        }
      ],
      "source": [
        "datasets = _data.get_datasets(\n",
        "    \"var_5_50_nosm_20000\",\n",
        "    datadirpath=\"/content/sochischool/listops/data_processing/python/listops/data\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "51f4befb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51f4befb",
        "outputId": "c9d7b28a-e321-44b5-d623-aaaac2d88ea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ds\n",
            "<listops.data_processing.python.datasets.MultiListOpsDataset object at 0x7f8e58227bd0>\n",
            "ds\n",
            "<listops.data_processing.python.datasets.MultiListOpsDataset object at 0x7f8e3f8ac190>\n",
            "ds\n",
            "<listops.data_processing.python.datasets.MultiListOpsDataset object at 0x7f8e3d613090>\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader, test_loader  = _data.get_dataloaders(datasets, batchsize=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3e07ecb5",
      "metadata": {
        "id": "3e07ecb5"
      },
      "outputs": [],
      "source": [
        "from listops.data_processing.python.loading import ix_to_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "104fccae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "104fccae",
        "outputId": "051dee21-2d56-4fd4-ca53-a074b58270fd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-dbee122ae611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0melem\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ],
      "source": [
        "\" \".join([ix_to_word[elem] for elem in x[-6].numpy().tolist() if elem != 15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "ca79c601",
      "metadata": {
        "id": "ca79c601"
      },
      "outputs": [],
      "source": [
        "from torch_struct import DependencyCRF\n",
        "from listops.model_modules.sampler import DependencySampler, Sampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bede9166",
      "metadata": {
        "id": "bede9166"
      },
      "outputs": [],
      "source": [
        "class ProjectiveSampler(DependencySampler):\n",
        "\n",
        "    def __init__(self, noise, tau):\n",
        "        assert noise in set(['gumbel', 'gaussian'])\n",
        "        super(ProjectiveSampler, self).__init__(\"soft\", noise, tau, True, False)\n",
        "        \n",
        "    def inject_noise(self, A):\n",
        "        if self.noise == \"gumbel\":\n",
        "            u = torch.distributions.utils.clamp_probs(torch.rand_like(A))\n",
        "            g = u.log().neg().log().neg()\n",
        "            return (A + g) / self.tau\n",
        "        elif self.noise == \"gaussian\":\n",
        "            pass\n",
        "\n",
        "    def sample(self, A, lengths, mode):\n",
        "        if mode == \"soft\":\n",
        "            return DependencyCRF(self.inject_noise(A), lengths).marginals\n",
        "        elif mode == \"hard\":\n",
        "            return DependencyCRF(self.inject_noise(A), lengths).argmax.detach()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from listops.model_modules.func_customparse import arcmask_from_lengths\n",
        "def mask(sample, lengths):\n",
        "    maxlen = sample.shape[1]\n",
        "    diag_mask = torch.eye(maxlen, device=sample.device, dtype=bool).unsqueeze(0)\n",
        "    sample = sample.masked_fill(diag_mask, 0.0)\n",
        "    arcmask = arcmask_from_lengths(sample, lengths)\n",
        "    sample = sample.masked_fill(arcmask, 0.0)\n",
        "    return sample"
      ],
      "metadata": {
        "id": "3gn317FpveXX"
      },
      "id": "3gn317FpveXX",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IndependentSampler(Sampler):\n",
        "\n",
        "    def __init__(self, tau):\n",
        "        super(IndependentSampler, self).__init__(\"soft\", None, tau)\n",
        "\n",
        "    def forward_train(self, A, lengths=None):\n",
        "        sample = mask(self.sample(A, lengths, \"soft\"), lengths)\n",
        "        return sample\n",
        "\n",
        "    def forward_eval(self, A, lengths=None):\n",
        "        sample = mask(self.sample(A, lengths, 'hard'), lengths)\n",
        "        return sample\n",
        "\n",
        "    def inject_noise(self, A):\n",
        "        u = torch.distributions.utils.clamp_probs(torch.rand_like(A))\n",
        "        logistic = u.log() - u.neg().log1p()\n",
        "        return (A + logistic) / self.tau\n",
        "\n",
        "    def sample(self, A, lengths, mode):\n",
        "        if mode == \"soft\":\n",
        "            return self.inject_noise(A).sigmoid()\n",
        "        elif mode == \"hard\":\n",
        "            return (self.inject_noise(A.detach()) > 0.0).float()"
      ],
      "metadata": {
        "id": "gZK5vZqLqdSU"
      },
      "id": "gZK5vZqLqdSU",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "b1da39f4",
      "metadata": {
        "id": "b1da39f4"
      },
      "outputs": [],
      "source": [
        "sampler = ProjectiveSampler(\"gumbel\", 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "af56f017",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af56f017",
        "outputId": "aaee8d2e-2935-4a5c-b5d9-da2ad16b817e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ],
      "source": [
        "m = _model.get_school_model(sampler)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUE7FfwDfItY",
        "outputId": "55811b9e-e735-4f6e-b86f-3ea9eeae7746"
      },
      "id": "XUE7FfwDfItY",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (base): ModelBase(\n",
              "    (sampler): ProjectiveSampler()\n",
              "    (computer): KipfMLPGNN(\n",
              "      (embd): Embedding(16, 60, padding_idx=15)\n",
              "      (msg_fc1): ModuleList(\n",
              "        (0): Linear(in_features=120, out_features=60, bias=True)\n",
              "      )\n",
              "      (msg_fc2): ModuleList(\n",
              "        (0): Linear(in_features=60, out_features=60, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (decoder): Decoder(\n",
              "      (net): Sequential(\n",
              "        (0): Linear(in_features=60, out_features=60, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=60, out_features=60, bias=True)\n",
              "        (3): ReLU()\n",
              "        (4): Linear(in_features=60, out_features=10, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (archer): Archer(\n",
              "    (embd): Embedding(16, 60, padding_idx=15)\n",
              "    (head_lstm): LSTM(60, 60, batch_first=True, dropout=0.1)\n",
              "    (head_dropout): Dropout(p=0.1, inplace=False)\n",
              "    (modif_lstm): LSTM(60, 60, batch_first=True, dropout=0.1)\n",
              "    (modif_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "x2SMsR1GiOrS"
      },
      "id": "x2SMsR1GiOrS",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "286e9aa2",
      "metadata": {
        "id": "286e9aa2"
      },
      "outputs": [],
      "source": [
        "opt = torch.optim.AdamW(m.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "9170d898",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9170d898",
        "outputId": "6f04afa5-a8c2-46b9-af31-63fdbc089bba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [12:33<00:00,  2.66it/s]\n",
            "100%|██████████| 2000/2000 [12:27<00:00,  2.68it/s]\n"
          ]
        }
      ],
      "source": [
        "m.train()\n",
        "num_epochs = 2\n",
        "for _ in range(num_epochs):\n",
        "    for batch_idx, (x, y, arcs, lengths, depths) in enumerate(tqdm(train_loader)):\n",
        "        opt.zero_grad()\n",
        "        bs = x.shape[0]\n",
        "\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        arcs = arcs.cuda()\n",
        "        lengths = lengths.cuda()\n",
        "        \n",
        "        with torch.set_grad_enabled(True):\n",
        "            pred_logits = m(x, arcs, lengths)\n",
        "            loss = torch.nn.functional.cross_entropy(pred_logits, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        #print(\"loss: {:.3f}\".format(loss.cpu().item()))\n",
        "\n",
        "        #acc = (pred_logits.argmax(-1) == y).float().mean()\n",
        "        #print(\"acc: {:.3f}\".format(acc.cpu().item()))\n",
        "        #print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "06b9670a",
      "metadata": {
        "id": "06b9670a"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(x, sample, arcs, lengths):\n",
        "    one = torch.tensor(1.0).cuda() if sample.is_cuda else torch.tensor(1.0)\n",
        "    zero = torch.tensor(0.0).cuda() if sample.is_cuda else torch.tensor(0.0)\n",
        "    # Compute true/false positives/negatives for metric calculations.\n",
        "    maxlen = arcs.shape[-1]\n",
        "    pad_tn = maxlen - lengths\n",
        "    tp = torch.where(sample * arcs == 1.0, one, zero).sum((-1, -2))\n",
        "    tn = torch.where(sample + arcs == 0.0, one, zero).sum((-1, -2)) - pad_tn\n",
        "    fp = torch.where(sample - arcs == 1.0, one, zero).sum((-1, -2))\n",
        "    fn = torch.where(sample - arcs == -1.0, one, zero).sum((-1, -2))\n",
        "\n",
        "    # Calculate IoUs.\n",
        "    iou = torch.mean((tp) / (tp + fp + fn)).cpu()\n",
        "    # Calculate precision (attachment).\n",
        "    precision = torch.mean(tp / (tp + fp)).cpu()\n",
        "    # Calculate recall.\n",
        "    recall = torch.mean(tp / (tp + fn)).cpu()\n",
        "    # Calculate parse accuracy\n",
        "    parse_acc = (sample == arcs).all(-1).all(-1).float().mean()\n",
        "\n",
        "    # Clean computations\n",
        "    # Compute clean attch_score which ignores \"]\" symbol (requires acces to x)\n",
        "    close_ix = _loading.word_to_ix[']']\n",
        "    clean_mask = (x != close_ix).unsqueeze(1).expand_as(arcs) # expands along 2nd dimension\n",
        "    clean_mask = clean_mask & clean_mask.transpose(1, 2)\n",
        "\n",
        "    cltp = torch.where((sample * arcs == 1.0) * clean_mask, one, zero).sum((-1, -2))\n",
        "    cltn = torch.where((sample + arcs == 0.0) * clean_mask, one, zero).sum((-1, -2)) - pad_tn\n",
        "    clfp = torch.where((sample - arcs == 1.0) * clean_mask, one, zero).sum((-1, -2))\n",
        "    clfn = torch.where((sample - arcs == -1.0) * clean_mask, one, zero).sum((-1, -2))\n",
        "\n",
        "    # Calculate IoUs.\n",
        "    idx = (cltp + clfp + clfn) > 0\n",
        "    clious = torch.ones_like(cltp)\n",
        "    clious[idx] = cltp[idx] / (cltp + clfp + clfn)[idx]\n",
        "    cliou = clious.mean().cpu()\n",
        "    # Calculate precision (attachment).\n",
        "    idx = (cltp + clfp) > 0\n",
        "    clprecisions = torch.zeros_like(cltp)\n",
        "    clprecisions[idx] = cltp[idx] / (cltp + clfp)[idx]\n",
        "    clprecision = clprecisions.mean().cpu()\n",
        "    # Calculate recall.\n",
        "    idx = (cltp + clfn) > 0\n",
        "    clrecalls = torch.ones_like(cltp)\n",
        "    clrecalls[idx] = cltp[idx] / (cltp + clfn)[idx]\n",
        "    clrecall = clrecalls.mean().cpu()\n",
        "    # Calculate parse accuracy\n",
        "    clparse_acc = (sample * clean_mask == arcs * clean_mask).all(-1).all(-1).float().mean()\n",
        "\n",
        "    if torch.isnan(cliou) or torch.isnan(clprecision) or torch.isnan(clrecall) or torch.isnan(clparse_acc):\n",
        "        print('Found NaN in cl metrics')\n",
        "\n",
        "    return iou, cliou, precision, clprecision, recall, clrecall, parse_acc, clparse_acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.eval()\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "val_precs = []\n",
        "val_recs = []\n",
        "for batch_idx, (x, y, arcs, lengths, depths) in enumerate(tqdm(val_loader)):\n",
        "    x = x.cuda()\n",
        "    y = y.cuda()\n",
        "    arcs = arcs.cuda()\n",
        "    lengths = lengths.cuda()\n",
        "    with torch.no_grad():\n",
        "      pred_logits = m(x, arcs, lengths)\n",
        "      loss = torch.nn.functional.cross_entropy(pred_logits, y)\n",
        "      acc = (pred_logits.argmax(-1) == y).float().mean()\n",
        "      iou, cliou, precision, clprecision, recall, clrecall, parse_acc, clparse_acc = (compute_metrics(x, m.sample, arcs, lengths))\n",
        "\n",
        "    val_losses.append(loss.item())\n",
        "    val_accs.append(acc.item())\n",
        "    val_precs.append(precision.item())\n",
        "    val_recs.append(recall.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LVvsc53oz1c",
        "outputId": "bcd97b0a-d6be-44b7-ed18-4da52bd159c1"
      },
      "id": "2LVvsc53oz1c",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:13<00:00,  1.33s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "ac27ffd3",
      "metadata": {
        "id": "ac27ffd3"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "c6eb15ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6eb15ee",
        "outputId": "5e69c148-97b6-433c-e63a-354d92703c07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7222351759672165"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "np.mean(val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(val_accs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoMXGM6qpz4N",
        "outputId": "b8bbbce8-192b-4526-8eae-dcc7aa782ed8"
      },
      "id": "OoMXGM6qpz4N",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7559000372886657"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(val_precs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d01WMkH_p00w",
        "outputId": "c7af652d-e224-4e2f-90be-be4615a99d28"
      },
      "id": "d01WMkH_p00w",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.520668089389801"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(val_recs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pqpp2Zqp1zb",
        "outputId": "cc7cdc1e-c047-43bc-dab0-44384150559a"
      },
      "id": "-pqpp2Zqp1zb",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.520668089389801"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4HPs_ct2p3vJ"
      },
      "id": "4HPs_ct2p3vJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-01cVy2bwX1p"
      },
      "id": "-01cVy2bwX1p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8yZh77MzwX7Y"
      },
      "id": "8yZh77MzwX7Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = IndependentSampler(1.0)"
      ],
      "metadata": {
        "id": "GCwBNDHcwYA9"
      },
      "id": "GCwBNDHcwYA9",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = _model.get_school_model(sampler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS-uqqhuwYGo",
        "outputId": "3860aab7-1a03-4815-e37a-a57ec83002de"
      },
      "id": "qS-uqqhuwYGo",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvmXJcZ8wfJb",
        "outputId": "98977774-6f65-40b4-ea4d-d1d1a21d62c0"
      },
      "id": "UvmXJcZ8wfJb",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (base): ModelBase(\n",
              "    (sampler): IndependentSampler()\n",
              "    (computer): KipfMLPGNN(\n",
              "      (embd): Embedding(16, 60, padding_idx=15)\n",
              "      (msg_fc1): ModuleList(\n",
              "        (0): Linear(in_features=120, out_features=60, bias=True)\n",
              "      )\n",
              "      (msg_fc2): ModuleList(\n",
              "        (0): Linear(in_features=60, out_features=60, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (decoder): Decoder(\n",
              "      (net): Sequential(\n",
              "        (0): Linear(in_features=60, out_features=60, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=60, out_features=60, bias=True)\n",
              "        (3): ReLU()\n",
              "        (4): Linear(in_features=60, out_features=10, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (archer): Archer(\n",
              "    (embd): Embedding(16, 60, padding_idx=15)\n",
              "    (head_lstm): LSTM(60, 60, batch_first=True, dropout=0.1)\n",
              "    (head_dropout): Dropout(p=0.1, inplace=False)\n",
              "    (modif_lstm): LSTM(60, 60, batch_first=True, dropout=0.1)\n",
              "    (modif_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.AdamW(m.parameters())"
      ],
      "metadata": {
        "id": "wdHW3yExwfzt"
      },
      "id": "wdHW3yExwfzt",
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m.train()\n",
        "num_epochs = 2\n",
        "for _ in range(num_epochs):\n",
        "    for batch_idx, (x, y, arcs, lengths, depths) in enumerate(tqdm(train_loader)):\n",
        "        opt.zero_grad()\n",
        "        bs = x.shape[0]\n",
        "\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        arcs = arcs.cuda()\n",
        "        lengths = lengths.cuda()\n",
        "        \n",
        "        with torch.set_grad_enabled(True):\n",
        "            pred_logits = m(x, arcs, lengths)\n",
        "            loss = torch.nn.functional.cross_entropy(pred_logits, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        #print(\"loss: {:.3f}\".format(loss.cpu().item()))\n",
        "\n",
        "        #acc = (pred_logits.argmax(-1) == y).float().mean()\n",
        "        #print(\"acc: {:.3f}\".format(acc.cpu().item()))\n",
        "        #print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbZrwJ8ywjID",
        "outputId": "885c9ba0-1778-480e-dd3e-0d83e75e5804"
      },
      "id": "UbZrwJ8ywjID",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [03:14<00:00, 10.30it/s]\n",
            "100%|██████████| 2000/2000 [03:17<00:00, 10.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n8XtwcxDx3Wz"
      },
      "id": "n8XtwcxDx3Wz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m.eval()\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "val_precs = []\n",
        "val_recs = []\n",
        "for batch_idx, (x, y, arcs, lengths, depths) in enumerate(tqdm(val_loader)):\n",
        "    x = x.cuda()\n",
        "    y = y.cuda()\n",
        "    arcs = arcs.cuda()\n",
        "    lengths = lengths.cuda()\n",
        "    with torch.no_grad():\n",
        "      pred_logits = m(x, arcs, lengths)\n",
        "      loss = torch.nn.functional.cross_entropy(pred_logits, y)\n",
        "      acc = (pred_logits.argmax(-1) == y).float().mean()\n",
        "      iou, cliou, precision, clprecision, recall, clrecall, parse_acc, clparse_acc = (compute_metrics(x, m.sample, arcs, lengths))\n",
        "\n",
        "    val_losses.append(loss.item())\n",
        "    val_accs.append(acc.item())\n",
        "    val_precs.append(precision.item())\n",
        "    val_recs.append(recall.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq688fnRyUNe",
        "outputId": "1c60bd70-1b2a-48e0-b27b-1874b1153ba1"
      },
      "id": "aq688fnRyUNe",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShPtbhi2yoCw",
        "outputId": "25b16f51-0a3f-4dc5-d247-037b61c37acc"
      },
      "id": "ShPtbhi2yoCw",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6143985614180565"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(val_accs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG9VA4ZDyqlU",
        "outputId": "fe2703cd-6002-4702-da9a-fbe0382df06d"
      },
      "id": "nG9VA4ZDyqlU",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7788000345230103"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(val_precs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eOxt-E_yr44",
        "outputId": "379b8551-1127-4664-fe4f-7e5e5134e630"
      },
      "id": "7eOxt-E_yr44",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1949520453810692"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(val_recs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwujlXBAytP3",
        "outputId": "5f460ea2-4d7b-48c7-e08c-52f89d86da13"
      },
      "id": "QwujlXBAytP3",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3637669622898102"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HXcfDBDgza8o"
      },
      "id": "HXcfDBDgza8o",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "sst_sem.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}