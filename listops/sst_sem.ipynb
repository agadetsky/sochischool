{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7e0081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5a99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d5e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import listops.data as _data\n",
    "import listops.data_processing.python.loading as _loading\n",
    "import listops.model as _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "071d899d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_processing/python/listops/data/d2_ml50_nosm\n",
      "./data_processing/python/listops/data/d3_ml50_nosm\n",
      "./data_processing/python/listops/data/d4_ml50_nosm\n",
      "./data_processing/python/listops/data/d5_ml50_nosm\n",
      "./data_processing/python/listops/data/d1_ml50_nosm\n",
      "maxnums\n",
      "[20000, 2000, 2000]\n",
      "[2, 3, 4, 5]\n",
      "file path: ./data_processing/python/listops/data/d2_ml50_nosm/train.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n",
      "file path: ./data_processing/python/listops/data/d3_ml50_nosm/train.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n",
      "file path: ./data_processing/python/listops/data/d4_ml50_nosm/train.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n",
      "file path: ./data_processing/python/listops/data/d5_ml50_nosm/train.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n",
      "file path: ./data_processing/python/listops/data/d1_ml50_nosm/train.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n",
      "[2, 3, 4, 5]\n",
      "file path: ./data_processing/python/listops/data/d2_ml50_nosm/valid.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n",
      "file path: ./data_processing/python/listops/data/d3_ml50_nosm/valid.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n",
      "file path: ./data_processing/python/listops/data/d4_ml50_nosm/valid.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n",
      "file path: ./data_processing/python/listops/data/d5_ml50_nosm/valid.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n",
      "file path: ./data_processing/python/listops/data/d1_ml50_nosm/valid.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n",
      "[2, 3, 4, 5]\n",
      "file path: ./data_processing/python/listops/data/d2_ml50_nosm/test.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n",
      "file path: ./data_processing/python/listops/data/d3_ml50_nosm/test.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n",
      "file path: ./data_processing/python/listops/data/d4_ml50_nosm/test.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n",
      "file path: ./data_processing/python/listops/data/d5_ml50_nosm/test.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n",
      "file path: ./data_processing/python/listops/data/d1_ml50_nosm/test.tsv\n",
      "number of skipped sentences due to length > inf: 0\n",
      "number of skipped sentences due to length < 2: 0\n"
     ]
    }
   ],
   "source": [
    "datasets = _data.get_datasets(\"var_5_50_nosm_20000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f4befb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds\n",
      "<listops.data_processing.python.datasets.MultiListOpsDataset object at 0x7f8e98168650>\n",
      "ds\n",
      "<listops.data_processing.python.datasets.MultiListOpsDataset object at 0x7f8e488680d0>\n",
      "ds\n",
      "<listops.data_processing.python.datasets.MultiListOpsDataset object at 0x7f8e03e71090>\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader  = _data.get_dataloaders(datasets, batchsize=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1081f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x - tokens\n",
    "y - value\n",
    "arcs - true graph\n",
    "lengths\n",
    "depths\n",
    "\"\"\"\n",
    "\n",
    "x, y, arcs, lengths, depths = next(iter(train_loader)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e07ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from listops.data_processing.python.loading import ix_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "104fccae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MIN 0 0 9 7 ]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([ix_to_word[elem] for elem in x[-6].numpy().tolist() if elem != 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca79c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_struct import DependencyCRF\n",
    "from listops.model_modules.sampler import DependencySampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bede9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectiveSampler(DependencySampler):\n",
    "\n",
    "    def __init__(self, noise, tau):\n",
    "        assert noise in set(['gumbel', 'gaussian'])\n",
    "        super(ProjectiveSampler, self).__init__(\"soft\", noise, tau, True, False)\n",
    "        \n",
    "    def inject_noise(self, A):\n",
    "        if self.noise == \"gumbel\":\n",
    "            u = torch.distributions.utils.clamp_probs(torch.rand_like(A))\n",
    "            g = u.log().neg().log().neg()\n",
    "            return (A + g) / self.tau\n",
    "        elif self.noise == \"gaussian\":\n",
    "            pass \n",
    "\n",
    "    def sample(self, A, lengths, mode):\n",
    "        if mode == \"soft\":\n",
    "            return DependencyCRF(self.inject_noise(A), lengths).marginals\n",
    "        elif mode == \"hard\":\n",
    "            return DependencyCRF(self.inject_noise(A), lengths).argmax.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1da39f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ProjectiveSampler(\"gumbel\", 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af56f017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agadetsky/miniconda3/envs/python37/lib/python3.7/site-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "m = _model.get_school_model(sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36c9e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = m(x, arcs, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "286e9aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW(m.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9170d898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.457\n",
      "acc: 0.420\n",
      "\n",
      "loss: 1.687\n",
      "acc: 0.460\n",
      "\n",
      "loss: 1.527\n",
      "acc: 0.320\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k1/9m231bzd0fd1zykgt6rrhfj00000gn/T/ipykernel_79646/821938278.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpred_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/sochischool/listops/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, arcs, lengths, training_mode)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0marc_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to parse arcs for gt archer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marc_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sampler never depends on tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mcomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# computer only depends on sample, not on arcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Save for easy access in .eval() to inspect sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/sochischool/listops/model_modules/gnn_modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;31m# messages are passed from children to parents.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             pred += self.single_step_forward(pred, senders_idxs=receivers,\n\u001b[0;32m--> 101\u001b[0;31m                                             receivers_idxs=senders, arcs=arcs)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/sochischool/listops/model_modules/gnn_modules.py\u001b[0m in \u001b[0;36msingle_step_forward\u001b[0;34m(self, E, senders_idxs, receivers_idxs, arcs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \"\"\"\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Node2edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0msenders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msenders_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# (bs, n ** 2 , embd_dim).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mreceivers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreceivers_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n ** 2, embd_dim).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mpre_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msenders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreceivers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch_idx, (x, y, arcs, lengths, depths) in enumerate(train_loader):\n",
    "    opt.zero_grad()\n",
    "    bs = x.shape[0]\n",
    "    \n",
    "    with torch.set_grad_enabled(True):\n",
    "        pred_logits = m(x, arcs, lengths)\n",
    "        loss = torch.nn.functional.cross_entropy(pred_logits, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print(\"loss: {:.3f}\".format(loss.item()))\n",
    "\n",
    "    acc = (pred_logits.argmax(-1) == y).float().mean()\n",
    "    print(\"acc: {:.3f}\".format(acc.item()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b77f00e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b3eee13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2000 * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18c6e25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f7ba900",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, arcs, lengths, depths = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df294cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (base): ModelBase(\n",
       "    (sampler): ProjectiveSampler()\n",
       "    (computer): KipfMLPGNN(\n",
       "      (embd): Embedding(16, 60, padding_idx=15)\n",
       "      (msg_fc1): ModuleList(\n",
       "        (0): Linear(in_features=120, out_features=60, bias=True)\n",
       "      )\n",
       "      (msg_fc2): ModuleList(\n",
       "        (0): Linear(in_features=60, out_features=60, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=60, out_features=60, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=60, out_features=60, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=60, out_features=10, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (archer): Archer(\n",
       "    (embd): Embedding(16, 60, padding_idx=15)\n",
       "    (head_lstm): LSTM(60, 60, batch_first=True, dropout=0.1)\n",
       "    (head_dropout): Dropout(p=0.1, inplace=False)\n",
       "    (modif_lstm): LSTM(60, 60, batch_first=True, dropout=0.1)\n",
       "    (modif_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c00a51b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = m(x, arcs, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db270f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 28, 28])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.sample.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06b9670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(x, sample, arcs, lengths):\n",
    "    one = torch.tensor(1.0).cuda() if sample.is_cuda else torch.tensor(1.0)\n",
    "    zero = torch.tensor(0.0).cuda() if sample.is_cuda else torch.tensor(0.0)\n",
    "    # Compute true/false positives/negatives for metric calculations.\n",
    "    maxlen = arcs.shape[-1]\n",
    "    pad_tn = maxlen - lengths\n",
    "    tp = torch.where(sample * arcs == 1.0, one, zero).sum((-1, -2))\n",
    "    tn = torch.where(sample + arcs == 0.0, one, zero).sum((-1, -2)) - pad_tn\n",
    "    fp = torch.where(sample - arcs == 1.0, one, zero).sum((-1, -2))\n",
    "    fn = torch.where(sample - arcs == -1.0, one, zero).sum((-1, -2))\n",
    "\n",
    "    # Calculate IoUs.\n",
    "    iou = torch.mean((tp) / (tp + fp + fn)).cpu()\n",
    "    # Calculate precision (attachment).\n",
    "    precision = torch.mean(tp / (tp + fp)).cpu()\n",
    "    # Calculate recall.\n",
    "    recall = torch.mean(tp / (tp + fn)).cpu()\n",
    "    # Calculate parse accuracy\n",
    "    parse_acc = (sample == arcs).all(-1).all(-1).float().mean()\n",
    "\n",
    "    # Clean computations\n",
    "    # Compute clean attch_score which ignores \"]\" symbol (requires acces to x)\n",
    "    close_ix = _loading.word_to_ix[']']\n",
    "    clean_mask = (x != close_ix).unsqueeze(1).expand_as(arcs) # expands along 2nd dimension\n",
    "    clean_mask = clean_mask & clean_mask.transpose(1, 2)\n",
    "\n",
    "    cltp = torch.where((sample * arcs == 1.0) * clean_mask, one, zero).sum((-1, -2))\n",
    "    cltn = torch.where((sample + arcs == 0.0) * clean_mask, one, zero).sum((-1, -2)) - pad_tn\n",
    "    clfp = torch.where((sample - arcs == 1.0) * clean_mask, one, zero).sum((-1, -2))\n",
    "    clfn = torch.where((sample - arcs == -1.0) * clean_mask, one, zero).sum((-1, -2))\n",
    "\n",
    "    # Calculate IoUs.\n",
    "    idx = (cltp + clfp + clfn) > 0\n",
    "    clious = torch.ones_like(cltp)\n",
    "    clious[idx] = cltp[idx] / (cltp + clfp + clfn)[idx]\n",
    "    cliou = clious.mean().cpu()\n",
    "    # Calculate precision (attachment).\n",
    "    idx = (cltp + clfp) > 0\n",
    "    clprecisions = torch.zeros_like(cltp)\n",
    "    clprecisions[idx] = cltp[idx] / (cltp + clfp)[idx]\n",
    "    clprecision = clprecisions.mean().cpu()\n",
    "    # Calculate recall.\n",
    "    idx = (cltp + clfn) > 0\n",
    "    clrecalls = torch.ones_like(cltp)\n",
    "    clrecalls[idx] = cltp[idx] / (cltp + clfn)[idx]\n",
    "    clrecall = clrecalls.mean().cpu()\n",
    "    # Calculate parse accuracy\n",
    "    clparse_acc = (sample * clean_mask == arcs * clean_mask).all(-1).all(-1).float().mean()\n",
    "\n",
    "    if torch.isnan(cliou) or torch.isnan(clprecision) or torch.isnan(clrecall) or torch.isnan(clparse_acc):\n",
    "        print('Found NaN in cl metrics')\n",
    "\n",
    "    return iou, cliou, precision, clprecision, recall, clrecall, parse_acc, clparse_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06f0df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou, cliou, precision, clprecision, recall, clrecall, parse_acc, clparse_acc = (compute_metrics(x, m.sample, arcs, lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27ffd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f2d30599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m.sample == arcs).all(-1).all(-1).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf445f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9748)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m.sample == arcs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3fdc08ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79330"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in m.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eb15ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
