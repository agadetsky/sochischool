{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://agadetsky@github.com/agadetsky/sochischool.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CNxcSwfbLxs",
        "outputId": "07ff0854-b01a-4202-ff9b-6df586423066"
      },
      "id": "1CNxcSwfbLxs",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sochischool'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects:  12% (1/8)\u001b[K\rremote: Counting objects:  25% (2/8)\u001b[K\rremote: Counting objects:  37% (3/8)\u001b[K\rremote: Counting objects:  50% (4/8)\u001b[K\rremote: Counting objects:  62% (5/8)\u001b[K\rremote: Counting objects:  75% (6/8)\u001b[K\rremote: Counting objects:  87% (7/8)\u001b[K\rremote: Counting objects: 100% (8/8)\u001b[K\rremote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 239 (delta 1), reused 2 (delta 0), pack-reused 231\u001b[K\n",
            "Receiving objects: 100% (239/239), 50.75 MiB | 28.81 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "Checking out files: 100% (194/194), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU git+https://github.com/harvardnlp/pytorch-struct"
      ],
      "metadata": {
        "id": "QEwPcViWbb-r"
      },
      "id": "QEwPcViWbb-r",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/sochischool/')"
      ],
      "metadata": {
        "id": "KVy40zmHbP6p"
      },
      "id": "KVy40zmHbP6p",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8a5a99b7",
      "metadata": {
        "id": "8a5a99b7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch_struct import DependencyCRF\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e6d5e694",
      "metadata": {
        "id": "e6d5e694"
      },
      "outputs": [],
      "source": [
        "import listops.data as _data\n",
        "import listops.data_processing.python.loading as _loading\n",
        "import listops.model as _model\n",
        "from listops.model_modules.sampler import DependencySampler, Sampler\n",
        "from listops.model_modules.func_customparse import arcmask_from_lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "071d899d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "071d899d",
        "outputId": "ce193cf0-77a8-490c-9183-4d57f9cff0cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sochischool/listops/data_processing/python/listops/data/d2_ml50_nosm\n",
            "/content/sochischool/listops/data_processing/python/listops/data/d3_ml50_nosm\n",
            "/content/sochischool/listops/data_processing/python/listops/data/d4_ml50_nosm\n",
            "/content/sochischool/listops/data_processing/python/listops/data/d5_ml50_nosm\n",
            "/content/sochischool/listops/data_processing/python/listops/data/d1_ml50_nosm\n",
            "maxnums\n",
            "[20000, 2000, 2000]\n",
            "[2, 3, 4, 5]\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d2_ml50_nosm/train.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d3_ml50_nosm/train.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d4_ml50_nosm/train.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d5_ml50_nosm/train.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d1_ml50_nosm/train.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "[2, 3, 4, 5]\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d2_ml50_nosm/valid.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d3_ml50_nosm/valid.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d4_ml50_nosm/valid.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d5_ml50_nosm/valid.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d1_ml50_nosm/valid.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "[2, 3, 4, 5]\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d2_ml50_nosm/test.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d3_ml50_nosm/test.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d4_ml50_nosm/test.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d5_ml50_nosm/test.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n",
            "file path: /content/sochischool/listops/data_processing/python/listops/data/d1_ml50_nosm/test.tsv\n",
            "number of skipped sentences due to length > inf: 0\n",
            "number of skipped sentences due to length < 2: 0\n"
          ]
        }
      ],
      "source": [
        "datasets = _data.get_datasets(\n",
        "    \"var_5_50_nosm_20000\",\n",
        "    datadirpath=\"/content/sochischool/listops/data_processing/python/listops/data\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "51f4befb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51f4befb",
        "outputId": "0ba045ff-5c68-4a5a-f193-49782d7c95d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ds\n",
            "<listops.data_processing.python.datasets.MultiListOpsDataset object at 0x7f59e7b7be90>\n",
            "ds\n",
            "<listops.data_processing.python.datasets.MultiListOpsDataset object at 0x7f59e233c0d0>\n",
            "ds\n",
            "<listops.data_processing.python.datasets.MultiListOpsDataset object at 0x7f59e5883050>\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader, test_loader  = _data.get_dataloaders(datasets, batchsize=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "104fccae",
      "metadata": {
        "id": "104fccae"
      },
      "outputs": [],
      "source": [
        "#\" \".join([_loading.ix_to_word[elem] for elem in x[-6].cpu().numpy().tolist() if elem != 15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bede9166",
      "metadata": {
        "id": "bede9166"
      },
      "outputs": [],
      "source": [
        "class ProjectiveSampler(DependencySampler):\n",
        "\n",
        "    def __init__(self, noise, tau):\n",
        "        assert noise in set(['gumbel', 'gaussian'])\n",
        "        super(ProjectiveSampler, self).__init__(\"soft\", noise, tau, True, False)\n",
        "        \n",
        "    def inject_noise(self, A):\n",
        "        if self.noise == \"gumbel\":\n",
        "            u = torch.distributions.utils.clamp_probs(torch.rand_like(A))\n",
        "            noise = u.log().neg().log().neg()\n",
        "            return (A + noise) / self.tau\n",
        "        elif self.noise == \"gaussian\":\n",
        "            noise = torch.randn_like(A)\n",
        "            return (A + noise) / self.tau\n",
        "\n",
        "    def sample(self, A, lengths, mode):\n",
        "        if mode == \"soft\":\n",
        "            return DependencyCRF(self.inject_noise(A), lengths).marginals\n",
        "        elif mode == \"hard\":\n",
        "            return DependencyCRF(self.inject_noise(A), lengths).argmax.detach()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mask(sample, lengths):\n",
        "    maxlen = sample.shape[1]\n",
        "    diag_mask = torch.eye(maxlen, device=sample.device, dtype=bool).unsqueeze(0)\n",
        "    sample = sample.masked_fill(diag_mask, 0.0)\n",
        "    arcmask = arcmask_from_lengths(sample, lengths)\n",
        "    sample = sample.masked_fill(arcmask, 0.0)\n",
        "    return sample"
      ],
      "metadata": {
        "id": "3gn317FpveXX"
      },
      "id": "3gn317FpveXX",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IndependentSampler(Sampler):\n",
        "\n",
        "    def __init__(self, noise, tau):\n",
        "        assert noise in set(['logistic'])\n",
        "        super(IndependentSampler, self).__init__(\"soft\", noise, tau)\n",
        "\n",
        "    def forward_train(self, A, lengths=None):\n",
        "        sample = mask(self.sample(A, lengths, \"soft\"), lengths)\n",
        "        return sample\n",
        "\n",
        "    def forward_eval(self, A, lengths=None):\n",
        "        sample = mask(self.sample(A, lengths, 'hard'), lengths)\n",
        "        return sample\n",
        "\n",
        "    def inject_noise(self, A):\n",
        "        if self.noise == \"logistic\":\n",
        "            u = torch.distributions.utils.clamp_probs(torch.rand_like(A))\n",
        "            noise = u.log() - u.neg().log1p()\n",
        "            return (A + noise) / self.tau\n",
        "\n",
        "    def sample(self, A, lengths, mode):\n",
        "        if mode == \"soft\":\n",
        "            return self.inject_noise(A).sigmoid()\n",
        "        elif mode == \"hard\":\n",
        "            return (self.inject_noise(A.detach()) > 0.0).float()"
      ],
      "metadata": {
        "id": "gZK5vZqLqdSU"
      },
      "id": "gZK5vZqLqdSU",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9170d898",
      "metadata": {
        "scrolled": true,
        "id": "9170d898"
      },
      "outputs": [],
      "source": [
        "def training(m, train_loader, opt, num_epochs):\n",
        "    m.train()\n",
        "    for _ in range(num_epochs):\n",
        "        for batch_idx, (x, y, arcs, lengths, depths) in enumerate(tqdm(train_loader)):\n",
        "            opt.zero_grad()\n",
        "\n",
        "            x = x.cuda()\n",
        "            y = y.cuda()\n",
        "            arcs = arcs.cuda()\n",
        "            lengths = lengths.cuda()\n",
        "            \n",
        "            with torch.set_grad_enabled(True):\n",
        "                pred_logits = m(x, arcs, lengths)\n",
        "                loss = torch.nn.functional.cross_entropy(pred_logits, y)\n",
        "                loss.backward()\n",
        "                opt.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "06b9670a",
      "metadata": {
        "id": "06b9670a"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(sample, arcs, lengths):\n",
        "    one = torch.tensor(1.0).cuda() if sample.is_cuda else torch.tensor(1.0)\n",
        "    zero = torch.tensor(0.0).cuda() if sample.is_cuda else torch.tensor(0.0)\n",
        "    # Compute true/false positives/negatives for metric calculations.\n",
        "    maxlen = arcs.shape[-1]\n",
        "    pad_tn = maxlen - lengths\n",
        "    tp = torch.where(sample * arcs == 1.0, one, zero).sum((-1, -2))\n",
        "    tn = torch.where(sample + arcs == 0.0, one, zero).sum((-1, -2)) - pad_tn\n",
        "    fp = torch.where(sample - arcs == 1.0, one, zero).sum((-1, -2))\n",
        "    fn = torch.where(sample - arcs == -1.0, one, zero).sum((-1, -2))\n",
        "\n",
        "    # Calculate precision (attachment).\n",
        "    precision = torch.mean(tp / (tp + fp)).cpu()\n",
        "    # Calculate recall.\n",
        "    recall = torch.mean(tp / (tp + fn)).cpu()\n",
        "\n",
        "    return precision, recall"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(m, val_loader):\n",
        "    m.eval()\n",
        "    val_losses = []\n",
        "    val_accs = []\n",
        "    val_precs = []\n",
        "    val_recs = []\n",
        "    for batch_idx, (x, y, arcs, lengths, depths) in enumerate(tqdm(val_loader)):\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        arcs = arcs.cuda()\n",
        "        lengths = lengths.cuda()\n",
        "        with torch.no_grad():\n",
        "          pred_logits = m(x, arcs, lengths)\n",
        "          loss = torch.nn.functional.cross_entropy(pred_logits, y)\n",
        "          acc = (pred_logits.argmax(-1) == y).float().mean()\n",
        "          precision, recall = (compute_metrics(m.sample, arcs, lengths))\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        val_accs.append(acc.item())\n",
        "        val_precs.append(precision.item())\n",
        "        val_recs.append(recall.item())\n",
        "    return val_losses, val_accs, val_precs, val_recs"
      ],
      "metadata": {
        "id": "2LVvsc53oz1c"
      },
      "id": "2LVvsc53oz1c",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ac27ffd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "ac27ffd3",
        "outputId": "94fc9b58-2980-4d8f-e6ab-7a7aad308738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "  7%|▋         | 148/2000 [00:13<02:43, 11.36it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d87e66e44768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-84e688668874>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(m, train_loader, opt, num_epochs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/sochischool/listops/data_processing/python/datasets.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     63\u001b[0m                             for seq in  [tokens, labels, arcmats, lengths, depths]]\n\u001b[1;32m     64\u001b[0m         tokens = torch.nn.utils.rnn.pad_sequence(sorted_seqs[0],\n\u001b[0;32m---> 65\u001b[0;31m                     batch_first=True, padding_value=PADDING_IDX)\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_seqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0marcmats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_seqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pad zeros, it is like these nodes do not exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;31m# assuming trailing dimensions and type of all the Tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;31m# in sequences are same and fetching those from sequences[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#sampler = ProjectiveSampler(\"gaussian\", 1.0)\n",
        "sampler = IndependentSampler(\"logistic\", 1.0)\n",
        "m = _model.get_school_model(sampler)\n",
        "m.cuda()\n",
        "opt = torch.optim.AdamW(m.parameters())\n",
        "training(m, train_loader, opt, num_epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_losses, val_accs, val_precs, val_recs = validation(m, val_loader)"
      ],
      "metadata": {
        "id": "9qu1vTdwCfMz",
        "outputId": "41afda2a-121a-4a58-fb5c-7bd4ab959bb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9qu1vTdwCfMz",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "c6eb15ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6eb15ee",
        "outputId": "13d49d06-8c33-4b8c-f5c0-dec0d8dea931"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.897117590904236"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "np.mean(val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(val_accs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoMXGM6qpz4N",
        "outputId": "1be3c971-0ea4-4294-e0f7-acee4014b3a9"
      },
      "id": "OoMXGM6qpz4N",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28240000903606416"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(val_precs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d01WMkH_p00w",
        "outputId": "d6d6d9b0-4fe2-493d-e174-f98c720055a0"
      },
      "id": "d01WMkH_p00w",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06232384238392115"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(val_recs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pqpp2Zqp1zb",
        "outputId": "a9739e7b-0572-4472-8e0b-27741a4eeb56"
      },
      "id": "-pqpp2Zqp1zb",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3070721298456192"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4HPs_ct2p3vJ"
      },
      "id": "4HPs_ct2p3vJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-01cVy2bwX1p"
      },
      "id": "-01cVy2bwX1p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8yZh77MzwX7Y"
      },
      "id": "8yZh77MzwX7Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n8XtwcxDx3Wz"
      },
      "id": "n8XtwcxDx3Wz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HXcfDBDgza8o"
      },
      "id": "HXcfDBDgza8o",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "sst_sem.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}